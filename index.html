<!DOCTYPE HTML>
<!--
	Spatial by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>

<head>
	<title>Fanxu Meng(孟繁续)@pku</title>
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<meta name="description" content="" />
	<meta name="keywords" content="" />
	<noscript>
		<link rel="stylesheet" href="css/style.css" />
		<link rel="stylesheet" href="css/skel.css" />
		<link rel="stylesheet" href="css/style-xlarge.css" />
	</noscript>
	<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Raleway:400,700">
	<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Open+Sans">
	<link rel="stylesheet" href="css/font-awesome.min.css">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<!--[if lte IE 8]><script src="js/html5shiv.js"></script><![endif]-->
	<script src="js/jquery.min.js"></script>
	<script src="js/skel.min.js"></script>
	<script src="js/skel-layers.min.js"></script>
	<script src="js/init.js"></script>
	<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
</head>

<body class="landing">

	<!-- Header -->
	<header id="header">
		<ul class="icons">
			<li>
				<a href="https://scholar.google.com/citations?user=xvfuhRUAAAAJ" class="icon fa-graduation-cap"></a>
			</li>
			<li>
				<a href="https://github.com/fxmeng" class="icon fa-github"></a>
			</li>
			<li>
				<a href="https://www.zhihu.com/people/meng-fan-xu-4" class="icon fa-twitter"></a>
			</li>
			<li>
				<a href="mailto:fxmeng@stu.pku.edu.cn" class="icon fa-envelope"></a>
			</li>
		</ul>
		<nav id="nav">
			<ul>
				<li><a href="/" class="active">Home</a></li>
				<li><a href="/#two">Publications</a></li>
				<li><a href="/#footer">Contact</a></li>
			</ul>
		</nav>
	</header>

	<!-- One -->
	<section id="one" class="wrapper style1">
		<div class="container 75%">
			<div class="row 200%">
				<div class="6u 12u$(medium)">
					<header class="major">
						<p>Fanxu Meng(孟繁续)</p>
						<p>
							<div class="image rounded" style="margin-bottom: 1.5em;"><img src="images/photo.jpg" width="200" alt="" /></div>
						</p>
					</header>
				</div>
				<div class="6u$ 12u$(medium)">
					<p>I am currently a Ph.D. student at the Institute for Artificial Intelligence, Peking University, under the supervision of <a href='https://muhanzhang.github.io'>Prof. Muhan Zhang</a>. 
						My research focuses on efficient LLMs and model compression. I have also served as a reviewer for NeurIPS, ICML, ICLR, COLM and TPAMI.</p>
				</div>
			</div>
		</div>
	</section>

	<!-- Two -->
	<section id="two" class="wrapper style2">
		<div class="container 75%">
			<h2 style="text-align: center">Selected Publications</h2>
			<hr />
			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
					<div class="image rounded"><img src="images/transmla.png" width="180" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<p><b>[NeurIPS 2025 spotlight (Top 3.19%)]</b> TransMLA: Multi-Head Latent Attention Is All You Need</p>
					<p>Proof MLA better than GQA and convert LLaMA, Qwen to Deepseek, (<a href='https://arxiv.org/abs/2502.07864'>Paper</a>, <a href="https://github.com/fxmeng/TransMLA">Code</a>, <a href="https://x.com/_akhaliq/status/1889870173055885452">Twitter</a>)</p>
					<p><b>Fanxu Meng<sup>*</sup></b>, Pingzhi Tang<sup>*</sup>, Xiaojuan Tang, Zengwei Yao, Xing Sun, Muhan Zhang.</p>
					</div>
			</div>
			<hr />
			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
					<div class="image rounded"><img src="images/hf_pissa.png" width="180" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<p><b>[EMNLP 2025 Oral]</b> HD-PiSSA: High-Rank Distributed Orthogonal Adaptation</p>
					<p>high-rank updates under data parallel fine-tuning, (<a href='https://arxiv.org/abs/2505.18777'>Paper</a>, <a href="https://github.com/MuLabPKU/HD-PiSSA">Code</a>)</p>
					<p><b>Yiding Wang<sup>*</sup></b>, Fanxu Meng<sup>*</sup>, Xuefeng Zhang, Fan Jiang, Pingzhi Tang, Muhan Zhang.</p>
					</div>
			</div>
			<hr />
			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
					<div class="image rounded"><img src="images/clover.png" width="180" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<p><b>[ICML 2025]</b> CLOVER: Cross-Layer Orthogonal Vectors Pruning and Fine-Tuning</p>
					<p>Absorb-Decompose for Pruning and Fine-Tuning, (<a href='https://arxiv.org/abs/2411.17426'>Paper</a>, <a href="https://github.com/fxmeng/CLOVER">Code</a>)</p>
					<p><b>Fanxu Meng</b>, Pingzhi Tang, Fan Jiang, Muhan Zhang.</p>
					</div>
			</div>
			<hr />
			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
					<div class="image rounded"><img src="images/pissa.png" width="180" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<p><b>[NeurIPS 2024 spotlight (Top 2.08%)]</b> PiSSA: Principal Singular values and Singular vectors Adaptation</p>
					<p>A faster and better LoRA initialization method, (<a href='https://arxiv.org/abs/2404.02948'>Paper</a>, <a href="https://github.com/GraphPKU/PiSSA">Code</a>, 
						<a href="https://github.com/huggingface/peft/tree/main/examples/pissa_finetuning">1</a>, 
						<a href="https://llamafactory.readthedocs.io/zh-cn/latest/advanced/adapters.html#pissa">2</a>, 
						<a href="https://wiki.rwkv.com/RWKV-Fine-Tuning/Pissa-Fine-Tuning.html#pissa-fine-tuning-tutorial">3</a>, 
						<a href="https://paddlenlp.readthedocs.io/en/latest/llm/docs/algorithm_overview.html#pissa">4</a>, 
						<a href="https://x.com/arankomatsuzaki/status/1777453185675973104">Twitter</a>,
						<a href="https://www.bilibili.com/video/BV1wi421e78B/?share_source=copy_web&vd_source=de7fbd68b3f46f40833c3f5defed104a">Talk</a>)</p>
					<p><b>Fanxu Meng</b>, Zhaohui Wang, Muhan Zhang.</p>
					</div>
			</div>
			<hr />
			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
					<div class="image rounded"><img src="images/rmnet.png" width="180" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<p>[Arxiv Preprint] RM -R ./Removing Residual Connection Equivalently</p>
					<p>A plug-in tricks for efficient pruning, (<a href='https://arxiv.org/abs/2111.00687'>Paper</a>, <a href="https://github.com/fxmeng/RMNet">Code</a>, <a href="https://course.zhidx.com/c/ZWQ0OTgyNGY2MzVmNGZlNjBhMTM=">Talk</a>)</p>
					<p><b>Fanxu Meng<sup>*</sup></b>, Hao Cheng<sup>*</sup>, Jiaxin Zhuang, Ke Li, Xing Sun.</p>
					</div>
			</div>
			<hr />
			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
					<div class="image rounded"><img src="images/swp.png" width="180" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<p><b>[NeurIPS 2020]</b> Pruning Filter in Filter</p>
					<p>Stripe wise pruning, (<a href='https://arxiv.org/abs/2009.14410'>Paper</a>, <a href="https://github.com/fxmeng/Pruning-Filter-in-Filter">Code</a>, <a href="https://course.zhidx.com/c/NWM2OTYxYTgxN2Q2NzVmNjQ1NjM=">Talk</a>)</p>
					<p><b>Fanxu Meng<sup>*</sup></b>, Hao Cheng<sup>*</sup>, Ke Li, Huixiang Luo, Xiaowei Guo, Guangming Lu, Xing Sun.</p>
				</div>
			</div>
			<hr />
			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
					<div class="image rounded"><img src="images/grafting.png" width="180" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<p><b>[CVPR 2020]</b> Filter Grafting for Deep Neural Networks</p>
					<p>Reactivate invalid filter while training,(<a href='https://openaccess.thecvf.com/content_CVPR_2020/html/Meng_Filter_Grafting_for_Deep_Neural_Networks_CVPR_2020_paper.html'>Paper</a>, <a href="https://github.com/fxmeng/filter-grafting">Code</a>)</p>
					<p><b>Fanxu Meng<sup>*</sup></b>, Hao Cheng<sup>*</sup>, Ke Li, Zhixin Xu, Rongrong Ji, Xing Sun, Guangming Lu.</p>
				</div>
			</div>
		</div>
	</section>
	<!--
	<section id="three" class="wrapper style3 special">
		<div class="container 50%">

			<h2>Curriculum vitae</h2>
			<ul class="actions">
				<li><a href="CV_fanxumeng.pdf" class="button alt big">Download CV</a></li>
			</ul>
		</div>
	</section>
	 -->

	<section id="three" class="wrapper style3 special">
		<div class="container 50%">
			<h2>Get in touch</h2>
			<ul class="icons">
				<li>
					<a href="https://scholar.google.com/citations?user=xvfuhRUAAAAJ" class="icon fa-graduation-cap"></a>
				</li>
				<li>
					<a href="https://github.com/fxmeng" class="icon fa-github"></a>
				</li>
				<li>
					<a href="https://www.zhihu.com/people/meng-fan-xu-4" class="icon fa-twitter"></a>
				</li>
				<li>
				<a href="mailto:fxmeng@stu.pku.edu.cn" class="icon fa-envelope"></a>
				</li>
			</ul>
		</div>
	</section>
	<!-- Footer -->
	<footer id="footer">
		<div class="container">
			<ul class="copyright">
				<li>&copy; 2022 Fanxu Meng</li>
			</ul>
		</div>
	</footer>

</body>

</html>
